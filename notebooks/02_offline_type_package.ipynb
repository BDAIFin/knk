{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fbab34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_parquet(\"data/offline/test_raw.parquet\")\n",
    "print(df.shape, df[\"fraud\"].mean(), df[\"fraud\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c4bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f = df[df[\"fraud\"] == 1].copy()\n",
    "print(\"fraud-only:\", df_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83217745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OFFLINE.features.client_state import add_client_state_feature\n",
    "\n",
    "class Cfg:\n",
    "    client_col = \"client_id\"\n",
    "\n",
    "df_f_feat = add_client_state_feature(df_f, Cfg)\n",
    "print(\"fraud-only + client_state:\", df_f_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OFFLINE.models.type_package import TypeDiscoveryConfig, make_type_discovery_matrix\n",
    "\n",
    "# 1) label/id 제외 전부 쓰고 싶으면 feature_cols=None 그대로 두면 됨\n",
    "cfg = TypeDiscoveryConfig(\n",
    "    label_col=\"fraud\",\n",
    "    id_cols=(\"client_id\",\"card_id\",\"merchant_id\"),\n",
    "    feature_cols=None,         # 전체 사용 (먼저 돌려보고, 이후 줄이는 걸 추천)\n",
    "    use_scaler=True,\n",
    "    fillna_value=0.0,\n",
    "\n",
    "    # GMM\n",
    "    gmm_k_min=2,\n",
    "    gmm_k_max=12,\n",
    "    gmm_covariance_type=\"full\",\n",
    "    compute_silhouette=True,\n",
    "    silhouette_sample_size=30000,\n",
    "\n",
    "    # HDBSCAN\n",
    "    hdb_min_cluster_size=50,\n",
    "    hdb_min_samples=None\n",
    ")\n",
    "\n",
    "X, feat_cols, scaler = make_type_discovery_matrix(df_f_feat, cfg)\n",
    "print(X.shape, len(feat_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7d90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OFFLINE.models.type_package import fit_gmm_best, profile_clusters, save_type_package\n",
    "\n",
    "gmm, best_k, gmm_scores = fit_gmm_best(X, cfg)\n",
    "print(\"best_k:\", best_k)\n",
    "gmm_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eae3d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_gmm = gmm.predict(X)  # hard label\n",
    "proba_gmm = gmm.predict_proba(X)  # soft membership (너희 프로젝트에 매우 유리)\n",
    "\n",
    "report_gmm = {\n",
    "    \"best_k\": int(best_k),\n",
    "    \"gmm_scores\": gmm_scores.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "profile_gmm = profile_clusters(df_f_feat, labels_gmm, feat_cols, topn=12)\n",
    "report_gmm[\"profile\"] = profile_gmm\n",
    "\n",
    "# 저장\n",
    "out_dir = f\"artifacts/type_package_v1/gmm\"\n",
    "save_type_package(\n",
    "    out_dir=out_dir,\n",
    "    algo=\"gmm\",\n",
    "    model=gmm,\n",
    "    scaler=scaler,\n",
    "    feature_cols=feat_cols,\n",
    "    cfg=cfg,\n",
    "    extra=report_gmm,\n",
    ")\n",
    "print(\"saved:\", out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f39369",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OFFLINE.models.type_package import fit_hdbscan\n",
    "\n",
    "hdb, labels_hdb = fit_hdbscan(X, cfg)\n",
    "print(\"unique labels:\", np.unique(labels_hdb)[:20], \" ...\")\n",
    "print(\"n_noise:\", (labels_hdb==-1).sum(), \"noise_ratio:\", (labels_hdb==-1).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a589642",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_hdb = {\n",
    "    \"hdbscan_params\": {\n",
    "        \"min_cluster_size\": cfg.hdb_min_cluster_size,\n",
    "        \"min_samples\": cfg.hdb_min_samples,\n",
    "        \"metric\": cfg.hdb_metric,\n",
    "        \"cluster_selection_method\": cfg.hdb_cluster_selection_method,\n",
    "    }\n",
    "}\n",
    "profile_hdb = profile_clusters(df_f_feat, labels_hdb, feat_cols, topn=12)\n",
    "report_hdb[\"profile\"] = profile_hdb\n",
    "\n",
    "out_dir = f\"artifacts/type_package_v1/hdbscan\"\n",
    "save_type_package(\n",
    "    out_dir=out_dir,\n",
    "    algo=\"hdbscan\",\n",
    "    model=hdb,\n",
    "    scaler=scaler,\n",
    "    feature_cols=feat_cols,\n",
    "    cfg=cfg,\n",
    "    extra=report_hdb,\n",
    ")\n",
    "print(\"saved:\", out_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f95911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from OFFLINE.models.type_package import fit_hdbscan, profile_clusters\n",
    "\n",
    "cands = [20, 30, 50, 80, 120, 200]\n",
    "rows = []\n",
    "\n",
    "for mcs in cands:\n",
    "    cfg2 = cfg\n",
    "    cfg2.hdb_min_cluster_size = mcs\n",
    "\n",
    "    hdb, labels = fit_hdbscan(X, cfg2)\n",
    "    prof = profile_clusters(df_f_feat, labels, feat_cols, topn=8)\n",
    "    rows.append({\n",
    "        \"min_cluster_size\": mcs,\n",
    "        \"n_clusters_ex_noise\": prof[\"n_clusters_ex_noise\"],\n",
    "        \"noise_ratio\": prof[\"noise_ratio\"],\n",
    "        \"largest_cluster\": max(prof[\"cluster_counts\"].values()),\n",
    "    })\n",
    "\n",
    "pd.DataFrame(rows).sort_values([\"noise_ratio\",\"n_clusters_ex_noise\"])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
