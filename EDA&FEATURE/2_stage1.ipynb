{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884418d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faedcde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../DATA/dataset/TRAIN_stage1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d5478",
   "metadata": {},
   "source": [
    "---\n",
    "# 다중공선성 check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "516e487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"fraud\"])\n",
    "corr = X.corr().abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce24fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>level_1</th>\n",
       "      <th>corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>amount_vs_client_avg_diff</td>\n",
       "      <td>amount_deviation</td>\n",
       "      <td>0.971414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>log_abs_amount</td>\n",
       "      <td>amount_vs_client_avg_diff</td>\n",
       "      <td>0.919937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>log_abs_amount</td>\n",
       "      <td>amount_deviation</td>\n",
       "      <td>0.895992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>card_fraud_last1</td>\n",
       "      <td>card_fraud_last3</td>\n",
       "      <td>0.848580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       level_0                    level_1      corr\n",
       "47   amount_vs_client_avg_diff           amount_deviation  0.971414\n",
       "1               log_abs_amount  amount_vs_client_avg_diff  0.919937\n",
       "2               log_abs_amount           amount_deviation  0.895992\n",
       "196           card_fraud_last1           card_fraud_last3  0.848580"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "\n",
    "high_corr_pairs = (\n",
    "    upper.stack()\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"corr\"})\n",
    "    .query(\"corr >= 0.8\")\n",
    "    .sort_values(\"corr\", ascending=False)\n",
    ")\n",
    "\n",
    "high_corr_pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e90df0",
   "metadata": {},
   "source": [
    "즉시성 -> last 1 살림\\\n",
    "\n",
    "| 변수                        | 의미                |\n",
    "| ------------------------- | ----------------- |\n",
    "| log_abs_amount            | 절대 규모             |\n",
    "| amount_vs_client_avg_diff | 평균 대비 차이          |\n",
    "| amount_deviation          | 평균 대비 표준화 z-score |\n",
    "\n",
    "-> amount_deviation이 제일 정보 압축 + 스케일 안정 \n",
    "\n",
    "[유지]\n",
    "- log_abs_amount\n",
    "- amount_deviation\n",
    "- card_fraud_last1\n",
    "\n",
    "[제거]\n",
    "- amount_vs_client_avg_diff\n",
    "- card_fraud_last3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb68548",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"amount_vs_client_avg_diff\", \"card_fraud_last3\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9f7130",
   "metadata": {},
   "source": [
    "---\n",
    "# SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4aa66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols: 23 cat_cols: 0\n"
     ]
    }
   ],
   "source": [
    "LABEL_COL = \"fraud\"  \n",
    "\n",
    "y = df[LABEL_COL].astype(int)\n",
    "X = df.drop(columns=[LABEL_COL])\n",
    "\n",
    "# 1) 컬럼 타입 자동 추정\n",
    "\n",
    "cat_cols = [c for c in X.columns if str(X[c].dtype) in (\"object\", \"category\")]\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "print(\"num_cols:\", len(num_cols), \"cat_cols:\", len(cat_cols))\n",
    "\n",
    "\n",
    "# 2) Train/Valid split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3) 간단 전처리 파이프\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)), \n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", num_pipe, num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2948ba42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid's auc: 0.930985\tvalid's average_precision: 0.573383\n",
      "best_iter: 41\n",
      "best_score: defaultdict(<class 'collections.OrderedDict'>, {'valid': OrderedDict([('auc', np.float64(0.9309853858465273)), ('average_precision', np.float64(0.5733826590611859))])})\n",
      "LGB AUC: 0.9309862609584562\n",
      "LGB PR-AUC: 0.575246858541035\n",
      "\n",
      "Computing SHAP (LightGBM native)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1a73476ad64cccbd9ac2d5e53d00a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/534 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top SHAP features:\n",
      " client_fraud_last1             2.213367\n",
      "seconds_since_prev_tx          1.357237\n",
      "tx_hour                        1.076400\n",
      "card_velocity_spike_ratio      0.877179\n",
      "amount_deviation               0.721085\n",
      "mcc_highrisk_90                0.285328\n",
      "client_merchant_is_new         0.189004\n",
      "log_abs_amount                 0.086074\n",
      "card_fraud_last1               0.076221\n",
      "card_merchant_is_new           0.044432\n",
      "hour_cos                       0.023145\n",
      "is_highrisk_weekday            0.018885\n",
      "tx_month                       0.013154\n",
      "card_mcc_is_new                0.008688\n",
      "client_mcc_is_new              0.003291\n",
      "high_amount                    0.001729\n",
      "err_bad_cvv                    0.001469\n",
      "has_error                      0.001329\n",
      "client_error_last1             0.000745\n",
      "err_bad_card_number            0.000536\n",
      "err_bad_expiration             0.000421\n",
      "card_error_last1               0.000180\n",
      "merchant_is_new_x_has_error    0.000036\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "X_train_lgb = X_train.copy()\n",
    "X_valid_lgb = X_valid.copy()\n",
    "\n",
    "dtrain = lgb.Dataset(X_train_lgb, label=y_train, free_raw_data=False)\n",
    "dvalid = lgb.Dataset(X_valid_lgb, label=y_valid, free_raw_data=False)\n",
    "\n",
    "params = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=[\"auc\", \"average_precision\"],\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    min_data_in_leaf=200,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "bst = lgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[dvalid],\n",
    "    valid_names=[\"valid\"],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(200, verbose=True),\n",
    "        lgb.log_evaluation(0),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"best_iter:\", bst.best_iteration)\n",
    "print(\"best_score:\", bst.best_score)\n",
    "\n",
    "pred_valid = bst.predict(X_valid_lgb, num_iteration=bst.best_iteration)\n",
    "print(\"LGB AUC:\", roc_auc_score(y_valid, pred_valid))\n",
    "print(\"LGB PR-AUC:\", average_precision_score(y_valid, pred_valid))\n",
    "\n",
    "\n",
    "# SHAP with tqdm (batch version)\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sv = X_valid_lgb\n",
    "\n",
    "batch_size = 2000\n",
    "all_contrib = []\n",
    "\n",
    "print(\"\\nComputing SHAP (LightGBM native)...\")\n",
    "\n",
    "for i in tqdm(range(0, len(sv), batch_size)):\n",
    "    batch = sv.iloc[i:i+batch_size]\n",
    "    contrib = bst.predict(batch, pred_contrib=True)\n",
    "    all_contrib.append(contrib[:, :-1])  # 마지막 열은 bias\n",
    "\n",
    "shap_values = np.vstack(all_contrib)\n",
    "\n",
    "imp = pd.Series(\n",
    "    np.abs(shap_values).mean(axis=0),\n",
    "    index=sv.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop SHAP features:\\n\", imp.head(30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da221e70",
   "metadata": {},
   "source": [
    "---\n",
    "# Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f91b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16ca304e8d64efea3a50cebc59fc248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 1:   0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] valid AUC=0.96969  PR-AUC=0.66117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439a77a2ac054410a3462e497539e73b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 2:   0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] valid AUC=0.97064  PR-AUC=0.68437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b7aefad8214c54ac848eaf6f441cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 3:   0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] valid AUC=0.97239  PR-AUC=0.68824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18f0b3b8d0f54de485d845606bf83595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 4:   0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 4] valid AUC=0.97282  PR-AUC=0.68471\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35fb2d8a38204e96945bbc093d2a588d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train epoch 5:   0%|          | 0/1042 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 5] valid AUC=0.97274  PR-AUC=0.68993\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546250c9c2a54232b88d8621f97851c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "extract attention:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top Attention features:\n",
      " mcc_highrisk_90                0.153214\n",
      "amount_deviation               0.122909\n",
      "tx_hour                        0.099942\n",
      "client_merchant_is_new         0.068642\n",
      "hour_cos                       0.045899\n",
      "card_merchant_is_new           0.045857\n",
      "is_highrisk_weekday            0.042593\n",
      "log_abs_amount                 0.034374\n",
      "client_error_last1             0.033932\n",
      "merchant_is_new_x_has_error    0.032522\n",
      "card_error_last1               0.030472\n",
      "high_amount                    0.030145\n",
      "card_mcc_is_new                0.029999\n",
      "err_bad_expiration             0.026969\n",
      "client_fraud_last1             0.026301\n",
      "card_fraud_last1               0.025920\n",
      "err_bad_cvv                    0.022774\n",
      "card_velocity_spike_ratio      0.022345\n",
      "tx_month                       0.021643\n",
      "seconds_since_prev_tx          0.021176\n",
      "client_mcc_is_new              0.017835\n",
      "has_error                      0.015020\n",
      "err_bad_card_number            0.014238\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "feature_names = list(X_train.columns)\n",
    "n_features = len(feature_names)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xtr = scaler.fit_transform(X_train.values.astype(np.float32))\n",
    "Xva = scaler.transform(X_valid.values.astype(np.float32))\n",
    "\n",
    "ytr = y_train.values.astype(np.float32)\n",
    "yva = y_valid.values.astype(np.float32)\n",
    "\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "train_loader = DataLoader(TabDataset(Xtr, ytr), batch_size=4096, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(TabDataset(Xva, yva), batch_size=8192, shuffle=False, num_workers=0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 1) Attention layer (weights 반환)\n",
    "\n",
    "class AttnEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model=64, n_heads=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = nn.MultiheadAttention(d_model, n_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 4, d_model),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, return_attn=False):\n",
    "        # x: [B, T, D]\n",
    "        attn_out, attn_w = self.mha(x, x, x, need_weights=True, average_attn_weights=False)\n",
    "        x = self.ln1(x + attn_out)\n",
    "        x = self.ln2(x + self.ff(x))\n",
    "        if return_attn:\n",
    "            # attn_w: [B, heads, T, T]\n",
    "            return x, attn_w\n",
    "        return x\n",
    "\n",
    "\n",
    "# 2) Tabular Transformer (CLS 토큰 사용)\n",
    "\n",
    "class TabularAttentionModel(nn.Module):\n",
    "    def __init__(self, n_features, d_model=64, n_heads=4, n_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # feature별 1->d 투영 (각 feature마다 별도의 linear)\n",
    "        self.feat_proj = nn.ModuleList([nn.Linear(1, d_model) for _ in range(n_features)])\n",
    "\n",
    "        # CLS token\n",
    "        self.cls = nn.Parameter(torch.zeros(1, 1, d_model))\n",
    "        nn.init.normal_(self.cls, std=0.02)\n",
    "\n",
    "        self.layers = nn.ModuleList([AttnEncoderLayer(d_model, n_heads, dropout) for _ in range(n_layers)])\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, X, return_attn=False):\n",
    "        # X: [B, F]\n",
    "        B, F = X.shape\n",
    "\n",
    "        # feature tokens 만들기: [B, F, D]\n",
    "        toks = []\n",
    "        for j in range(F):\n",
    "            xj = X[:, j:j+1]                 # [B, 1]\n",
    "            toks.append(self.feat_proj[j](xj))  # [B, D]\n",
    "        tok = torch.stack(toks, dim=1)       # [B, F, D]\n",
    "\n",
    "        # CLS 붙이기: [B, 1+F, D]\n",
    "        cls = self.cls.expand(B, -1, -1)\n",
    "        x = torch.cat([cls, tok], dim=1)\n",
    "\n",
    "        attn_all = []\n",
    "        for layer in self.layers:\n",
    "            if return_attn:\n",
    "                x, attn = layer(x, return_attn=True)\n",
    "                attn_all.append(attn)\n",
    "            else:\n",
    "                x = layer(x, return_attn=False)\n",
    "\n",
    "        # CLS representation으로 예측\n",
    "        cls_repr = x[:, 0, :]               # [B, D]\n",
    "        logit = self.head(cls_repr).squeeze(1)\n",
    "\n",
    "        if return_attn:\n",
    "            return logit, attn_all  # list of [B, heads, T, T]\n",
    "        return logit\n",
    "\n",
    "\n",
    "# 3) 학습 루프\n",
    "\n",
    "model = TabularAttentionModel(n_features=n_features, d_model=64, n_heads=4, n_layers=2, dropout=0.1).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def eval_model():\n",
    "    model.eval()\n",
    "    ps, ys = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in valid_loader:\n",
    "            xb = xb.to(device)\n",
    "            logit = model(xb)\n",
    "            prob = torch.sigmoid(logit).cpu().numpy()\n",
    "            ps.append(prob)\n",
    "            ys.append(yb.numpy())\n",
    "    p = np.concatenate(ps)\n",
    "    t = np.concatenate(ys)\n",
    "    return roc_auc_score(t, p), average_precision_score(t, p)\n",
    "\n",
    "EPOCHS = 5\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader, desc=f\"train epoch {epoch}\", leave=False)\n",
    "    for xb, yb in pbar:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        logit = model(xb)\n",
    "        loss = loss_fn(logit, yb)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        pbar.set_postfix(loss=float(loss.detach().cpu()))\n",
    "\n",
    "    auc, pr = eval_model()\n",
    "    print(f\"[epoch {epoch}] valid AUC={auc:.5f}  PR-AUC={pr:.5f}\")\n",
    "\n",
    "\n",
    "# 4) Attention 추출 → 컬럼 중요도\n",
    "# - CLS(0번 토큰)에서 각 feature 토큰으로 가는 attention을 사용\n",
    "\n",
    "def extract_feature_attention_importance(model, loader, n_batches=50):\n",
    "    model.eval()\n",
    "    # 누적: feature별 attention 합\n",
    "    att_sum = np.zeros((n_features,), dtype=np.float64)\n",
    "    cnt = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for b, (xb, yb) in enumerate(tqdm(loader, desc=\"extract attention\", total=min(n_batches, len(loader)))):\n",
    "            if b >= n_batches:\n",
    "                break\n",
    "            xb = xb.to(device)\n",
    "\n",
    "            logit, attn_all = model(xb, return_attn=True)\n",
    "            attn = attn_all[-1]  # [B, heads, T, T]\n",
    "\n",
    "            # CLS -> feature 토큰 attention: query=0, key=1..F\n",
    "            # shape: [B, heads, F]\n",
    "            cls_to_feat = attn[:, :, 0, 1:]  \n",
    "\n",
    "            # heads 평균, batch 평균 → [F]\n",
    "            score = cls_to_feat.mean(dim=1).mean(dim=0).cpu().numpy()\n",
    "            att_sum += score\n",
    "            cnt += 1\n",
    "\n",
    "    att_mean = att_sum / max(cnt, 1)\n",
    "    imp = pd.Series(att_mean, index=feature_names).sort_values(ascending=False)\n",
    "    return imp\n",
    "\n",
    "att_imp = extract_feature_attention_importance(model, valid_loader, n_batches=50)\n",
    "print(\"\\nTop Attention features:\\n\", att_imp.head(30))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3386aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             shap_mean_abs  attn_cls2feat  shap_rank  \\\n",
      "client_fraud_last1                2.213367       0.026301        1.0   \n",
      "seconds_since_prev_tx             1.357237       0.021176        2.0   \n",
      "tx_hour                           1.076400       0.099942        3.0   \n",
      "card_velocity_spike_ratio         0.877179       0.022345        4.0   \n",
      "amount_deviation                  0.721085       0.122909        5.0   \n",
      "mcc_highrisk_90                   0.285328       0.153214        6.0   \n",
      "client_merchant_is_new            0.189004       0.068642        7.0   \n",
      "log_abs_amount                    0.086074       0.034374        8.0   \n",
      "card_fraud_last1                  0.076221       0.025920        9.0   \n",
      "card_merchant_is_new              0.044432       0.045857       10.0   \n",
      "hour_cos                          0.023145       0.045899       11.0   \n",
      "is_highrisk_weekday               0.018885       0.042593       12.0   \n",
      "tx_month                          0.013154       0.021643       13.0   \n",
      "card_mcc_is_new                   0.008688       0.029999       14.0   \n",
      "client_mcc_is_new                 0.003291       0.017835       15.0   \n",
      "high_amount                       0.001729       0.030145       16.0   \n",
      "err_bad_cvv                       0.001469       0.022774       17.0   \n",
      "has_error                         0.001329       0.015020       18.0   \n",
      "client_error_last1                0.000745       0.033932       19.0   \n",
      "err_bad_card_number               0.000536       0.014238       20.0   \n",
      "err_bad_expiration                0.000421       0.026969       21.0   \n",
      "card_error_last1                  0.000180       0.030472       22.0   \n",
      "merchant_is_new_x_has_error       0.000036       0.032522       23.0   \n",
      "\n",
      "                             attn_rank  rank_gap  \n",
      "client_fraud_last1                15.0      14.0  \n",
      "seconds_since_prev_tx             20.0      18.0  \n",
      "tx_hour                            3.0       0.0  \n",
      "card_velocity_spike_ratio         18.0      14.0  \n",
      "amount_deviation                   2.0      -3.0  \n",
      "mcc_highrisk_90                    1.0      -5.0  \n",
      "client_merchant_is_new             4.0      -3.0  \n",
      "log_abs_amount                     8.0       0.0  \n",
      "card_fraud_last1                  16.0       7.0  \n",
      "card_merchant_is_new               6.0      -4.0  \n",
      "hour_cos                           5.0      -6.0  \n",
      "is_highrisk_weekday                7.0      -5.0  \n",
      "tx_month                          19.0       6.0  \n",
      "card_mcc_is_new                   13.0      -1.0  \n",
      "client_mcc_is_new                 21.0       6.0  \n",
      "high_amount                       12.0      -4.0  \n",
      "err_bad_cvv                       17.0       0.0  \n",
      "has_error                         22.0       4.0  \n",
      "client_error_last1                 9.0     -10.0  \n",
      "err_bad_card_number               23.0       3.0  \n",
      "err_bad_expiration                14.0      -7.0  \n",
      "card_error_last1                  11.0     -11.0  \n",
      "merchant_is_new_x_has_error       10.0     -13.0  \n"
     ]
    }
   ],
   "source": [
    "compare = pd.DataFrame({\n",
    "    \"shap_mean_abs\": imp,        \n",
    "    \"attn_cls2feat\": att_imp\n",
    "}).fillna(0.0)\n",
    "\n",
    "compare[\"shap_rank\"] = compare[\"shap_mean_abs\"].rank(ascending=False, method=\"min\")\n",
    "compare[\"attn_rank\"] = compare[\"attn_cls2feat\"].rank(ascending=False, method=\"min\")\n",
    "compare[\"rank_gap\"] = compare[\"attn_rank\"] - compare[\"shap_rank\"]\n",
    "\n",
    "print(compare.sort_values(\"shap_mean_abs\", ascending=False).head(40))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59586e4e",
   "metadata": {},
   "source": [
    "---\n",
    "# Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7de1fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "params = dict(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=64,\n",
    "    min_data_in_leaf=200,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "def train_eval(X_tr, y_tr, X_va, y_va):\n",
    "    dtrain = lgb.Dataset(X_tr, label=y_tr, free_raw_data=False)\n",
    "    dvalid = lgb.Dataset(X_va, label=y_va, free_raw_data=False)\n",
    "\n",
    "    bst = lgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=3000,\n",
    "        valid_sets=[dvalid],\n",
    "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(0)],\n",
    "    )\n",
    "\n",
    "    pred = bst.predict(X_va, num_iteration=bst.best_iteration)\n",
    "\n",
    "    return {\n",
    "        \"auc\": roc_auc_score(y_va, pred),\n",
    "        \"prauc\": average_precision_score(y_va, pred),\n",
    "        \"best_iter\": bst.best_iteration,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99bb12c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.930985\n",
      "BASE: {'auc': 0.9309862609584562, 'prauc': 0.575246858541035, 'best_iter': 41}\n"
     ]
    }
   ],
   "source": [
    "base_result = train_eval(X_train, y_train, X_valid, y_valid)\n",
    "print(\"BASE:\", base_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6ccf1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48dde0437114015a8ab39922e48ad5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.95168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.9519\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951737\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.950553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951736\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.951736\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.952628\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.952031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.952653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.952653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.9527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.944553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.953025\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.953025\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.952704\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.952505\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's auc: 0.95269\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropped_feature</th>\n",
       "      <th>auc_drop</th>\n",
       "      <th>prauc_drop</th>\n",
       "      <th>auc</th>\n",
       "      <th>prauc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mcc_highrisk_90</td>\n",
       "      <td>-0.013567</td>\n",
       "      <td>-0.080113</td>\n",
       "      <td>0.944553</td>\n",
       "      <td>0.655360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>card_fraud_last1</td>\n",
       "      <td>-0.019567</td>\n",
       "      <td>0.046422</td>\n",
       "      <td>0.950553</td>\n",
       "      <td>0.528825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>log_abs_amount</td>\n",
       "      <td>-0.020694</td>\n",
       "      <td>-0.079517</td>\n",
       "      <td>0.951680</td>\n",
       "      <td>0.654764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>client_fraud_last1</td>\n",
       "      <td>-0.020750</td>\n",
       "      <td>-0.080199</td>\n",
       "      <td>0.951736</td>\n",
       "      <td>0.655445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tx_hour</td>\n",
       "      <td>-0.020750</td>\n",
       "      <td>-0.080199</td>\n",
       "      <td>0.951736</td>\n",
       "      <td>0.655445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high_amount</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>0.951737</td>\n",
       "      <td>0.655440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>has_error</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>0.951737</td>\n",
       "      <td>0.655440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>card_error_last1</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>0.951737</td>\n",
       "      <td>0.655440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>err_bad_expiration</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>0.951737</td>\n",
       "      <td>0.655440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>err_bad_cvv</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>0.951737</td>\n",
       "      <td>0.655440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>err_bad_card_number</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>0.951737</td>\n",
       "      <td>0.655440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>client_error_last1</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.080193</td>\n",
       "      <td>0.951737</td>\n",
       "      <td>0.655440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amount_deviation</td>\n",
       "      <td>-0.020914</td>\n",
       "      <td>-0.080041</td>\n",
       "      <td>0.951900</td>\n",
       "      <td>0.655288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hour_cos</td>\n",
       "      <td>-0.021045</td>\n",
       "      <td>-0.084221</td>\n",
       "      <td>0.952031</td>\n",
       "      <td>0.659468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>client_merchant_is_new</td>\n",
       "      <td>-0.021519</td>\n",
       "      <td>-0.087525</td>\n",
       "      <td>0.952505</td>\n",
       "      <td>0.662772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tx_month</td>\n",
       "      <td>-0.021642</td>\n",
       "      <td>-0.082988</td>\n",
       "      <td>0.952628</td>\n",
       "      <td>0.658234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is_highrisk_weekday</td>\n",
       "      <td>-0.021666</td>\n",
       "      <td>-0.084075</td>\n",
       "      <td>0.952653</td>\n",
       "      <td>0.659321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>seconds_since_prev_tx</td>\n",
       "      <td>-0.021666</td>\n",
       "      <td>-0.084075</td>\n",
       "      <td>0.952653</td>\n",
       "      <td>0.659321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>merchant_is_new_x_has_error</td>\n",
       "      <td>-0.021704</td>\n",
       "      <td>-0.090627</td>\n",
       "      <td>0.952690</td>\n",
       "      <td>0.665873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>card_velocity_spike_ratio</td>\n",
       "      <td>-0.021714</td>\n",
       "      <td>-0.090003</td>\n",
       "      <td>0.952700</td>\n",
       "      <td>0.665250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>card_merchant_is_new</td>\n",
       "      <td>-0.021717</td>\n",
       "      <td>-0.096179</td>\n",
       "      <td>0.952704</td>\n",
       "      <td>0.671426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>card_mcc_is_new</td>\n",
       "      <td>-0.022038</td>\n",
       "      <td>-0.091294</td>\n",
       "      <td>0.953025</td>\n",
       "      <td>0.666541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>client_mcc_is_new</td>\n",
       "      <td>-0.022038</td>\n",
       "      <td>-0.091294</td>\n",
       "      <td>0.953025</td>\n",
       "      <td>0.666541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dropped_feature  auc_drop  prauc_drop       auc     prauc\n",
       "17              mcc_highrisk_90 -0.013567   -0.080113  0.944553  0.655360\n",
       "9              card_fraud_last1 -0.019567    0.046422  0.950553  0.528825\n",
       "0                log_abs_amount -0.020694   -0.079517  0.951680  0.654764\n",
       "10           client_fraud_last1 -0.020750   -0.080199  0.951736  0.655445\n",
       "11                      tx_hour -0.020750   -0.080199  0.951736  0.655445\n",
       "1                   high_amount -0.020751   -0.080193  0.951737  0.655440\n",
       "3                     has_error -0.020751   -0.080193  0.951737  0.655440\n",
       "7              card_error_last1 -0.020751   -0.080193  0.951737  0.655440\n",
       "6            err_bad_expiration -0.020751   -0.080193  0.951737  0.655440\n",
       "4                   err_bad_cvv -0.020751   -0.080193  0.951737  0.655440\n",
       "5           err_bad_card_number -0.020751   -0.080193  0.951737  0.655440\n",
       "8            client_error_last1 -0.020751   -0.080193  0.951737  0.655440\n",
       "2              amount_deviation -0.020914   -0.080041  0.951900  0.655288\n",
       "13                     hour_cos -0.021045   -0.084221  0.952031  0.659468\n",
       "21       client_merchant_is_new -0.021519   -0.087525  0.952505  0.662772\n",
       "12                     tx_month -0.021642   -0.082988  0.952628  0.658234\n",
       "14          is_highrisk_weekday -0.021666   -0.084075  0.952653  0.659321\n",
       "15        seconds_since_prev_tx -0.021666   -0.084075  0.952653  0.659321\n",
       "22  merchant_is_new_x_has_error -0.021704   -0.090627  0.952690  0.665873\n",
       "16    card_velocity_spike_ratio -0.021714   -0.090003  0.952700  0.665250\n",
       "20         card_merchant_is_new -0.021717   -0.096179  0.952704  0.671426\n",
       "18              card_mcc_is_new -0.022038   -0.091294  0.953025  0.666541\n",
       "19            client_mcc_is_new -0.022038   -0.091294  0.953025  0.666541"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_one_results = []\n",
    "\n",
    "for col in tqdm(X_train.columns):\n",
    "    cols = [c for c in X_train.columns if c != col]\n",
    "\n",
    "    res = train_eval(\n",
    "        X_train[cols],\n",
    "        y_train,\n",
    "        X_valid[cols],\n",
    "        y_valid,\n",
    "    )\n",
    "\n",
    "    drop_one_results.append({\n",
    "        \"dropped_feature\": col,\n",
    "        \"auc_drop\": base_result[\"auc\"] - res[\"auc\"],\n",
    "        \"prauc_drop\": base_result[\"prauc\"] - res[\"prauc\"],\n",
    "        \"auc\": res[\"auc\"],\n",
    "        \"prauc\": res[\"prauc\"],\n",
    "    })\n",
    "\n",
    "drop_one_df = pd.DataFrame(drop_one_results)\\\n",
    "    .sort_values(\"auc_drop\", ascending=False)\n",
    "\n",
    "drop_one_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e07e58",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39555668",
   "metadata": {},
   "source": [
    "# Stage1 Feature Selection Summary\n",
    "\n",
    "(SHAP + Attention + Ablation 종합 정리)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Strong Keep (핵심 유지)\n",
    "\n",
    "| Feature                     | 근거                            |\n",
    "| --------------------------- | ----------------------------- |\n",
    "| `client_fraud_last1`        | SHAP 1위, 모델 의존도 매우 높음         |\n",
    "| `seconds_since_prev_tx`     | SHAP 2위, 실시간 이상 패턴 포착         |\n",
    "| `tx_hour`                   | SHAP/Attention 상위             |\n",
    "| `card_velocity_spike_ratio` | Velocity 신호, ablation 영향 큼    |\n",
    "| `amount_deviation`          | Amount anomaly 핵심             |\n",
    "| `mcc_highrisk_90`           | Attention 1위, 제거 시 AUC 감소     |\n",
    "| `client_merchant_is_new`    | SHAP/Attention/ablation 모두 중요 |\n",
    "\n",
    "이들은 Stage1 리스크 구조의 중심 축.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Keep (유지 권장)\n",
    "\n",
    "| Feature                | 근거                 |\n",
    "| ---------------------- | ------------------ |\n",
    "| `log_abs_amount`       | 기본 금액 강도           |\n",
    "| `card_fraud_last1`     | 카드 단위 과거 리스크       |\n",
    "| `card_merchant_is_new` | 신규 상점 신호           |\n",
    "| `hour_cos`             | 시간 패턴 보조           |\n",
    "| `is_highrisk_weekday`  | 요일 리스크 보조          |\n",
    "| `tx_month`             | 계절성 보조             |\n",
    "| `card_mcc_is_new`      | 신규 MCC             |\n",
    "| `client_mcc_is_new`    | 신규 MCC (client 기준) |\n",
    "\n",
    "보조적이지만 구조적 의미가 있음.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Drop 후보 (기여도 낮음)\n",
    "\n",
    "| Feature                       | 근거         |\n",
    "| ----------------------------- | ---------- |\n",
    "| `high_amount`                 | SHAP 매우 낮음 |\n",
    "| `err_bad_cvv`                 | 영향 미미      |\n",
    "| `has_error`                   | 단독 기여 낮음   |\n",
    "| `client_error_last1`          | 기여도 매우 낮음  |\n",
    "| `err_bad_card_number`         | 낮음         |\n",
    "| `err_bad_expiration`          | 낮음         |\n",
    "| `card_error_last1`            | 거의 영향 없음   |\n",
    "| `merchant_is_new_x_has_error` | 영향 거의 없음   |\n",
    "\n",
    "제거해도 성능 변화가 거의 없을 가능성 높음.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Stage1 구조 해석\n",
    "\n",
    "현재 Stage1 모델은 다음 6개 축으로 구성됨:\n",
    "\n",
    "1. Fraud history\n",
    "2. Velocity\n",
    "3. Time\n",
    "4. MCC high-risk\n",
    "5. Merchant novelty\n",
    "6. Amount anomaly\n",
    "\n",
    "Error 세부 변수들은 Stage2로 넘기는 것이 구조적으로 적절.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Slim Stage1 제안 (가볍게)\n",
    "\n",
    "```python\n",
    "CORE_STAGE1 = [\n",
    "    \"log_abs_amount\",\n",
    "    \"amount_deviation\",\n",
    "    \"client_fraud_last1\",\n",
    "    \"card_fraud_last1\",\n",
    "    \"seconds_since_prev_tx\",\n",
    "    \"card_velocity_spike_ratio\",\n",
    "    \"tx_hour\",\n",
    "    \"hour_cos\",\n",
    "    \"mcc_highrisk_90\",\n",
    "    \"client_merchant_is_new\",\n",
    "    \"card_merchant_is_new\",\n",
    "]\n",
    "```\n",
    "\n",
    "이 구성은:\n",
    "\n",
    "* 실시간성 유지\n",
    "* 계산 부담 최소화\n",
    "* 구조적 리스크 축 유지\n",
    "* 중복 신호 제거\n",
    "\n",
    "Stage1을 “빠르고 가볍게” 유지하면서도 성능을 크게 훼손하지 않을 가능성이 높음.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3e6e2b7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "STRONG_KEEP = [\n",
    "    \"client_fraud_last1\",\n",
    "    \"seconds_since_prev_tx\",\n",
    "    \"tx_hour\",\n",
    "    \"card_velocity_spike_ratio\",\n",
    "    \"amount_deviation\",\n",
    "    \"mcc_highrisk_90\",\n",
    "    \"client_merchant_is_new\",\n",
    "]\n",
    "\n",
    "KEEP = [\n",
    "    \"log_abs_amount\",\n",
    "    \"card_fraud_last1\",\n",
    "    \"card_merchant_is_new\",\n",
    "    \"hour_cos\",\n",
    "    \"is_highrisk_weekday\",\n",
    "    \"tx_month\",\n",
    "    \"card_mcc_is_new\",\n",
    "    \"client_mcc_is_new\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU-CAT)",
   "language": "python",
   "name": "gpu-cat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
