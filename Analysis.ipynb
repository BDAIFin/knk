{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0e9843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8851561 entries, 0 to 8851560\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Dtype         \n",
      "---  ------               -----         \n",
      " 0   date                 datetime64[ns]\n",
      " 1   client_id            int32         \n",
      " 2   card_id              int32         \n",
      " 3   amount               float32       \n",
      " 4   use_chip             category      \n",
      " 5   merchant_id          int32         \n",
      " 6   merchant_city        category      \n",
      " 7   merchant_state       category      \n",
      " 8   zip                  category      \n",
      " 9   mcc                  int16         \n",
      " 10  fraud                int8          \n",
      " 11  has_error            int8          \n",
      " 12  err_card_credential  int8          \n",
      " 13  err_authentication   int8          \n",
      " 14  err_financial        int8          \n",
      " 15  err_system           int8          \n",
      "dtypes: category(4), datetime64[ns](1), float32(1), int16(1), int32(3), int8(6)\n",
      "memory usage: 323.8 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet(\"transactions_clean.parquet\")\n",
    "\n",
    "# Datetime\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "\n",
    "# ID columns\n",
    "df[\"client_id\"]   = df[\"client_id\"].astype(\"int32\")\n",
    "df[\"card_id\"]     = df[\"card_id\"].astype(\"int32\")\n",
    "df[\"merchant_id\"] = df[\"merchant_id\"].astype(\"int32\")\n",
    "df[\"mcc\"]         = df[\"mcc\"].astype(\"int16\")\n",
    "\n",
    "# Amount\n",
    "df[\"amount\"] = df[\"amount\"].astype(\"float32\")\n",
    "\n",
    "# Categorical features\n",
    "for c in [\"use_chip\", \"merchant_city\", \"merchant_state\", \"zip\"]:\n",
    "    df[c] = df[c].astype(\"category\")\n",
    "\n",
    "# Error flags\n",
    "for c in [\n",
    "    \"has_error\",\n",
    "    \"err_card_credential\",\n",
    "    \"err_authentication\",\n",
    "    \"err_financial\",\n",
    "    \"err_system\"\n",
    "]:\n",
    "    df[c] = df[c].astype(\"int8\")\n",
    "\n",
    "# Target\n",
    "df[\"fraud\"] = df[\"fraud\"].astype(\"int8\")\n",
    "\n",
    "df.info(memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606d3329",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = df.copy()\n",
    "user = pd.read_csv(\"user_common.csv\")\n",
    "card = pd.read_csv(\"card_common.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542a936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_fraud: 10013 n_nonfraud: 8841548\n",
      "        dataset  fraud  nonfraud  total  \\\n",
      "0  fraud_1_to_1  10013     10013  20026   \n",
      "1  fraud_1_to_3  10013     30039  40052   \n",
      "2  fraud_1_to_5  10013     50065  60078   \n",
      "3  fraud_1_to_7  10013     70091  80104   \n",
      "\n",
      "                                      path  \n",
      "0  data/sampling/fraud_1_to_1/data.parquet  \n",
      "1  data/sampling/fraud_1_to_3/data.parquet  \n",
      "2  data/sampling/fraud_1_to_5/data.parquet  \n",
      "3  data/sampling/fraud_1_to_7/data.parquet  \n",
      "remainder_nonfraud: 8681340 saved -> data/sampling/remainder_nonfraud.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# 0) 설정\n",
    "# =========================\n",
    "base_path = \"data/sampling\"\n",
    "ratios = [1, 3, 5, 7]\n",
    "seed = 42\n",
    "\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 1) fraud / nonfraud split\n",
    "# =========================\n",
    "fraud_df = trans[trans[\"fraud\"] == 1].copy()\n",
    "nonfraud_df = trans[trans[\"fraud\"] == 0].copy()\n",
    "\n",
    "n_fraud = len(fraud_df)\n",
    "print(\"n_fraud:\", n_fraud, \"n_nonfraud:\", len(nonfraud_df))\n",
    "\n",
    "# nonfraud 셔플 (겹치지 않게 자를 거라 중요)\n",
    "nonfraud_df = nonfraud_df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# =========================\n",
    "# 2) ratio별 nonfraud chunk 생성 + 저장\n",
    "# =========================\n",
    "cursor = 0\n",
    "meta = []\n",
    "\n",
    "for r in ratios:\n",
    "    need = r * n_fraud\n",
    "\n",
    "    if cursor + need > len(nonfraud_df):\n",
    "        print(f\"[STOP] nonfraud 부족: 1:{r} 필요 {need}, 남은 {len(nonfraud_df)-cursor}\")\n",
    "        break\n",
    "\n",
    "    nonfraud_part = nonfraud_df.iloc[cursor:cursor+need].copy()\n",
    "    cursor += need\n",
    "\n",
    "    df_r = (\n",
    "        pd.concat([fraud_df, nonfraud_part], axis=0)\n",
    "        .sample(frac=1, random_state=seed)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    folder = f\"{base_path}/fraud_1_to_{r}\"\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    out_path = f\"{folder}/data.parquet\"\n",
    "    df_r.to_parquet(out_path, index=False)\n",
    "\n",
    "    meta.append({\n",
    "        \"dataset\": f\"fraud_1_to_{r}\",\n",
    "        \"fraud\": int((df_r[\"fraud\"] == 1).sum()),\n",
    "        \"nonfraud\": int((df_r[\"fraud\"] == 0).sum()),\n",
    "        \"total\": int(len(df_r)),\n",
    "        \"path\": out_path\n",
    "    })\n",
    "\n",
    "# =========================\n",
    "# 3) 남은 nonfraud 저장 \n",
    "# =========================\n",
    "remainder = nonfraud_df.iloc[cursor:].copy()\n",
    "remainder_path = f\"{base_path}/remainder_nonfraud.parquet\"\n",
    "remainder.to_parquet(remainder_path, index=False)\n",
    "\n",
    "meta_df = pd.DataFrame(meta)\n",
    "print(meta_df)\n",
    "print(\"remainder_nonfraud:\", len(remainder), \"saved ->\", remainder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066c6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "base_path = \"data/sampling\"\n",
    "ratio_names = [\"fraud_1_to_1\", \"fraud_1_to_3\", \"fraud_1_to_5\", \"fraud_1_to_7\"]\n",
    "\n",
    "def summarize_results(res_df: pd.DataFrame):\n",
    "    summary = (\n",
    "        res_df\n",
    "        .groupby(\"variable\")\n",
    "        .agg(\n",
    "            sign_consistent=(\"beta\", lambda x: len(set(np.sign(x))) == 1),\n",
    "            significant_cnt=(\"pvalue\", lambda x: (x < 0.05).sum()),\n",
    "            mean_or=(\"odds_ratio\", \"mean\"),\n",
    "            min_or=(\"odds_ratio\", \"min\"),\n",
    "            max_or=(\"odds_ratio\", \"max\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .sort_values([\"sign_consistent\", \"significant_cnt\"], ascending=False)\n",
    "    )\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ccb15f",
   "metadata": {},
   "source": [
    "## 4.1 WHEN — 시간 기반 분석\n",
    "\n",
    "### 목적\n",
    "\n",
    "- 정상 거래 대비 **시간적 패턴 이탈 여부** 식별\n",
    "\n",
    "### 사용 컬럼\n",
    "\n",
    "**Transactions**\n",
    "\n",
    "- `date`\n",
    "\n",
    "**Card**\n",
    "\n",
    "- `acct_open_date`\n",
    "- `expires`\n",
    "- `year_pin_last_changed`\n",
    "\n",
    "**User**\n",
    "\n",
    "- `birth_year` (나이 계산용)\n",
    "\n",
    "### 제외/축소 컬럼\n",
    "\n",
    "- `birth_month`\n",
    "- `retirement_age`\n",
    "\n",
    "### 주요 가설\n",
    "\n",
    "- 비정상 시간대(야간, 새벽) 거래에서 Fraud 발생률 증가\n",
    "- 카드 개설 직후 또는 만료 임박 시점의 거래 위험 증가\n",
    "- PIN 장기간 미변경 카드에서 Fraud 발생률 증가\n",
    "\n",
    "### 파생 피처 후보\n",
    "\n",
    "- 거래 시각 관련: `hour`, `is_night`\n",
    "- 카드 상태: `days_since_card_open`, `days_to_expire`\n",
    "- 보안 상태: `years_since_pin_change`\n",
    "- 사용자 상태: `age_at_transaction`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57adc959",
   "metadata": {},
   "source": [
    "### **가설1: OFF-HOUR에서 Fraud 증가? (타깃=fraud)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03181c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dataset     variable      beta  odds_ratio        pvalue\n",
      "0  fraud_1_to_1  is_off_hour -0.790488    0.453624  1.161750e-22\n",
      "1  fraud_1_to_3  is_off_hour -0.765320    0.465185  1.169183e-34\n",
      "2  fraud_1_to_5  is_off_hour -0.841352    0.431127  2.443010e-51\n",
      "3  fraud_1_to_7  is_off_hour -0.891096    0.410206  8.605636e-64\n",
      "      variable  sign_consistent  significant_cnt   mean_or    min_or    max_or\n",
      "0  is_off_hour             True                4  0.440035  0.410206  0.465185\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name in ratio_names:\n",
    "    df = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    df[\"hour\"] = df[\"date\"].dt.hour\n",
    "    df[\"is_off_hour\"] = ((df[\"hour\"] <= 5) | (df[\"hour\"] >= 22)).astype(int)\n",
    "\n",
    "    y = df[\"fraud\"].astype(int)\n",
    "\n",
    "    X = df[[\"is_off_hour\", \"amount\", \"use_chip\"]].copy()\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X = sm.add_constant(X, has_constant=\"add\").astype(float)\n",
    "\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "    var = \"is_off_hour\"\n",
    "    results.append({\n",
    "        \"dataset\": name,\n",
    "        \"variable\": var,\n",
    "        \"beta\": float(model.params[var]),\n",
    "        \"odds_ratio\": float(np.exp(model.params[var])),\n",
    "        \"pvalue\": float(model.pvalues[var]),\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df)\n",
    "print(summarize_results(res_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be79fce",
   "metadata": {},
   "source": [
    "off-hour 거래는 정상 시간대 거래에 비해\n",
    "Fraud일 확률이 약 55~60% 낮다\n",
    "\n",
    "(OR ≈ 0.44 → 1 − 0.44 ≈ 56%)\n",
    "\n",
    "*비정상 시간대(야간·새벽) 거래에서 Fraud 발생률 증가 -> 가설 기각*\n",
    "\n",
    "> **Fraud는 비정상 시간대의 이벤트라기보다, 정상 소비 패턴 안에서 발생하는 구조적 현상이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979fbaf7",
   "metadata": {},
   "source": [
    "### **가설2: 카드 개설 직후/만료 임박 거래가 더 위험? (타깃=fraud)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5956bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3428328/1887910223.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  card[\"acct_open_date\"] = pd.to_datetime(card[\"acct_open_date\"])\n",
      "/tmp/ipykernel_3428328/1887910223.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  card[\"expires\"] = pd.to_datetime(card[\"expires\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dataset         variable      beta  odds_ratio        pvalue\n",
      "0  fraud_1_to_1  days_since_open -0.000067    0.999933  6.168393e-06\n",
      "1  fraud_1_to_1   days_to_expire  0.000121    1.000121  3.991284e-09\n",
      "2  fraud_1_to_3  days_since_open -0.000077    0.999923  6.942762e-12\n",
      "3  fraud_1_to_3   days_to_expire  0.000181    1.000181  1.307703e-31\n",
      "4  fraud_1_to_5  days_since_open -0.000075    0.999925  4.098268e-14\n",
      "5  fraud_1_to_5   days_to_expire  0.000198    1.000198  1.026477e-48\n",
      "6  fraud_1_to_7  days_since_open -0.000077    0.999923  3.698385e-17\n",
      "7  fraud_1_to_7   days_to_expire  0.000194    1.000194  2.085107e-53\n",
      "          variable  sign_consistent  significant_cnt   mean_or    min_or  \\\n",
      "0  days_since_open             True                4  0.999926  0.999923   \n",
      "1   days_to_expire             True                4  1.000173  1.000121   \n",
      "\n",
      "     max_or  \n",
      "0  0.999933  \n",
      "1  1.000198  \n"
     ]
    }
   ],
   "source": [
    "# card 전처리 \n",
    "card[\"acct_open_date\"] = pd.to_datetime(card[\"acct_open_date\"])\n",
    "card[\"expires\"] = pd.to_datetime(card[\"expires\"])\n",
    "\n",
    "results = []\n",
    "\n",
    "for name in ratio_names:\n",
    "    df = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    df[\"hour\"] = df[\"date\"].dt.hour\n",
    "    df[\"is_off_hour\"] = ((df[\"hour\"] <= 5) | (df[\"hour\"] >= 22)).astype(int)\n",
    "\n",
    "    df = df.merge(\n",
    "        card[[\"id\", \"acct_open_date\", \"expires\"]],\n",
    "        left_on=\"card_id\",\n",
    "        right_on=\"id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df[\"days_since_open\"] = (df[\"date\"] - df[\"acct_open_date\"]).dt.days\n",
    "    df[\"days_to_expire\"] = (df[\"expires\"] - df[\"date\"]).dt.days\n",
    "\n",
    "    df = df.dropna(subset=[\"days_since_open\", \"days_to_expire\"])\n",
    "    df = df[(df[\"days_since_open\"] >= 0) & (df[\"days_to_expire\"] >= -365)]\n",
    "\n",
    "    y = df[\"fraud\"].astype(int)\n",
    "\n",
    "    X = df[[\"days_since_open\", \"days_to_expire\", \"amount\", \"use_chip\", \"is_off_hour\"]].copy()\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X = sm.add_constant(X, has_constant=\"add\").astype(float)\n",
    "\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "    for var in [\"days_since_open\", \"days_to_expire\"]:\n",
    "        results.append({\n",
    "            \"dataset\": name,\n",
    "            \"variable\": var,\n",
    "            \"beta\": float(model.params[var]),\n",
    "            \"odds_ratio\": float(np.exp(model.params[var])),\n",
    "            \"pvalue\": float(model.pvalues[var]),\n",
    "        })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df)\n",
    "print(summarize_results(res_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f5aec9",
   "metadata": {},
   "source": [
    "> **카드 생애 변수(개설 이후 기간, 만료까지 남은 기간)는**\\\n",
    "> **Fraud 발생과 통계적으로는 연관되지만,**\\\n",
    "> **실질적인 위험 설명력은 매우 제한적이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c152d",
   "metadata": {},
   "source": [
    "### **가설3: PIN 변경 시점(구간)과 Fraud 위험 (타깃=fraud)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df630c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset           variable      beta  odds_ratio        pvalue\n",
      "0   fraud_1_to_1   pin_age_grp_10y+ -0.922387    0.397569  1.572301e-05\n",
      "1   fraud_1_to_3   pin_age_grp_10y+ -1.243273    0.288439  2.789220e-14\n",
      "2   fraud_1_to_5   pin_age_grp_10y+ -1.308679    0.270177  1.160098e-18\n",
      "3   fraud_1_to_7   pin_age_grp_10y+ -1.147027    0.317580  1.230001e-15\n",
      "4   fraud_1_to_1   pin_age_grp_1–3y  0.072251    1.074925  2.776708e-01\n",
      "5   fraud_1_to_3   pin_age_grp_1–3y  0.078571    1.081740  1.246203e-01\n",
      "6   fraud_1_to_5   pin_age_grp_1–3y  0.027230    1.027604  5.489059e-01\n",
      "7   fraud_1_to_7   pin_age_grp_1–3y  0.000004    1.000004  9.999158e-01\n",
      "8   fraud_1_to_1   pin_age_grp_3–5y  0.276146    1.318040  6.746802e-05\n",
      "9   fraud_1_to_3   pin_age_grp_3–5y  0.129340    1.138077  1.449202e-02\n",
      "10  fraud_1_to_5   pin_age_grp_3–5y  0.130340    1.139215  5.510451e-03\n",
      "11  fraud_1_to_7   pin_age_grp_3–5y  0.086732    1.090605  4.744239e-02\n",
      "12  fraud_1_to_1  pin_age_grp_5–10y -0.416365    0.659440  4.017073e-09\n",
      "13  fraud_1_to_3  pin_age_grp_5–10y -0.483556    0.616587  3.324604e-19\n",
      "14  fraud_1_to_5  pin_age_grp_5–10y -0.516323    0.596710  5.877175e-27\n",
      "15  fraud_1_to_7  pin_age_grp_5–10y -0.544756    0.579984  9.333914e-34\n",
      "            variable  sign_consistent  significant_cnt   mean_or    min_or  \\\n",
      "0   pin_age_grp_10y+             True                4  0.318441  0.270177   \n",
      "2   pin_age_grp_3–5y             True                4  1.171484  1.090605   \n",
      "3  pin_age_grp_5–10y             True                4  0.613180  0.579984   \n",
      "1   pin_age_grp_1–3y             True                0  1.046068  1.000004   \n",
      "\n",
      "     max_or  \n",
      "0  0.397569  \n",
      "2  1.318040  \n",
      "3  0.659440  \n",
      "1  1.081740  \n"
     ]
    }
   ],
   "source": [
    "card[\"year_pin_last_changed\"] = pd.to_numeric(card[\"year_pin_last_changed\"], errors=\"coerce\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name in ratio_names:\n",
    "    df = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    # off-hour 재생성\n",
    "    df[\"hour\"] = df[\"date\"].dt.hour\n",
    "    df[\"is_off_hour\"] = ((df[\"hour\"] <= 5) | (df[\"hour\"] >= 22)).astype(int)\n",
    "\n",
    "    # card merge\n",
    "    df = df.merge(\n",
    "        card[[\"id\", \"year_pin_last_changed\"]],\n",
    "        left_on=\"card_id\",\n",
    "        right_on=\"id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df[\"txn_year\"] = df[\"date\"].dt.year\n",
    "    df[\"years_since_pin_change\"] = df[\"txn_year\"] - df[\"year_pin_last_changed\"]\n",
    "\n",
    "    df = df.dropna(subset=[\"years_since_pin_change\"])\n",
    "    df = df[df[\"years_since_pin_change\"] >= 0]\n",
    "\n",
    "    df[\"pin_age_grp\"] = pd.cut(\n",
    "        df[\"years_since_pin_change\"],\n",
    "        bins=[0, 1, 3, 5, 10, 50],\n",
    "        labels=[\"≤1y\", \"1–3y\", \"3–5y\", \"5–10y\", \"10y+\"]\n",
    "    )\n",
    "\n",
    "    y = df[\"fraud\"].astype(int)\n",
    "\n",
    "    X = df[[\"pin_age_grp\", \"amount\", \"use_chip\", \"is_off_hour\"]].copy()\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X = sm.add_constant(X, has_constant=\"add\").astype(float)\n",
    "\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "    for col in X.columns:\n",
    "        if col.startswith(\"pin_age_grp_\"):\n",
    "            results.append({\n",
    "                \"dataset\": name,\n",
    "                \"variable\": col,\n",
    "                \"beta\": float(model.params[col]),\n",
    "                \"odds_ratio\": float(np.exp(model.params[col])),\n",
    "                \"pvalue\": float(model.pvalues[col]),\n",
    "            })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "print(res_df.sort_values([\"variable\", \"dataset\"]).reset_index(drop=True))\n",
    "print(summarize_results(res_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c169727",
   "metadata": {},
   "source": [
    "> **PIN 변경 이후 3–5년 구간에서 Fraud 발생 확률이 가장 높으며,**\\\n",
    "**PIN 변경 후 10년 이상 경과한 카드는 Fraud 발생 확률이 유의하게 낮다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fca921",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 WHERE — 위치 기반 분석\n",
    "\n",
    "### 목적\n",
    "\n",
    "- 거래 위치의 **공간적 일관성 여부** 평가\n",
    "\n",
    "### 사용 컬럼\n",
    "\n",
    "**Transactions**\n",
    "\n",
    "- `merchant_state`\n",
    "- `zip`\n",
    "- `merchant_city` (보조)\n",
    "\n",
    "**User**\n",
    "\n",
    "- `latitude`\n",
    "- `longitude`\n",
    "\n",
    "### 제외/축소 컬럼\n",
    "\n",
    "- `address` (직접 사용 X)\n",
    "- `merchant_city`는 대표 위치 정보로 축소 가능\n",
    "\n",
    "### 주요 가설\n",
    "\n",
    "- 거주지와 지리적으로 먼 거래일수록 Fraud 위험 증가\n",
    "- 단시간 내 지역 급변 거래 패턴에서 Fraud 증가\n",
    "- `ONLINE` 거래는 오프라인 거래와 상이한 위험 분포를 가짐\n",
    "\n",
    "### 파생 피처 후보\n",
    "\n",
    "- `geo_distance(user ↔ merchant)`\n",
    "- `is_out_of_state`\n",
    "- `is_online`\n",
    "- `location_change_rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e3b5036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans[\"merchant_state\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b83a6a8",
   "metadata": {},
   "source": [
    "### **가설4: 주 활동 지역이 아닐 경우 fraud일 확률이 높다**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624271bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3428328/1675517024.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby([\"client_id\", \"merchant_state\"])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_out_of_state</th>\n",
       "      <th>fraud</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.514629</td>\n",
       "      <td>fraud_1_to_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.269070</td>\n",
       "      <td>fraud_1_to_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.260384</td>\n",
       "      <td>fraud_1_to_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.113428</td>\n",
       "      <td>fraud_1_to_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.174248</td>\n",
       "      <td>fraud_1_to_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.072038</td>\n",
       "      <td>fraud_1_to_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.130998</td>\n",
       "      <td>fraud_1_to_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.052468</td>\n",
       "      <td>fraud_1_to_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_out_of_state     fraud       dataset\n",
       "0                0  0.514629  fraud_1_to_1\n",
       "1                1  0.269070  fraud_1_to_1\n",
       "2                0  0.260384  fraud_1_to_3\n",
       "3                1  0.113428  fraud_1_to_3\n",
       "4                0  0.174248  fraud_1_to_5\n",
       "5                1  0.072038  fraud_1_to_5\n",
       "6                0  0.130998  fraud_1_to_7\n",
       "7                1  0.052468  fraud_1_to_7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_rows = []\n",
    "home_state = (\n",
    "    trans[trans.merchant_state != \"ONLINE\"]\n",
    "    .groupby([\"client_id\", \"merchant_state\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"cnt\")\n",
    "    .sort_values([\"client_id\", \"cnt\"], ascending=[True, False])\n",
    "    .drop_duplicates(\"client_id\")\n",
    "    .rename(columns={\"merchant_state\": \"home_state\"})\n",
    ")\n",
    "\n",
    "for name in ratio_names:\n",
    "    df_s = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    # is_online\n",
    "    df_s[\"is_online\"] = (\n",
    "        (df_s[\"merchant_state\"] == \"ONLINE\") |\n",
    "        (df_s[\"zip\"] == \"ONLINE\")\n",
    "    ).astype(int)\n",
    "\n",
    "    # home_state merge\n",
    "    df_s = df_s.merge(\n",
    "        home_state[[\"client_id\", \"home_state\"]],\n",
    "        on=\"client_id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # is_out_of_state\n",
    "    df_s[\"is_out_of_state\"] = (\n",
    "        (df_s[\"merchant_state\"] != df_s[\"home_state\"]) &\n",
    "        (df_s[\"is_online\"] == 0)\n",
    "    ).astype(int)\n",
    "\n",
    "    # EDA: fraud rate by out_of_state\n",
    "    grp = (\n",
    "        df_s.groupby(\"is_out_of_state\")[\"fraud\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    grp[\"dataset\"] = name\n",
    "    eda_rows.append(grp)\n",
    "\n",
    "eda_df = pd.concat(eda_rows, ignore_index=True)\n",
    "eda_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b346b",
   "metadata": {},
   "source": [
    "> **사용자 주 활동 지역을 벗어났다는 사실 자체는 Fraud 위험을 설명하지 못한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d29b23",
   "metadata": {},
   "source": [
    "### **가설5: ONLINE` 거래는 오프라인 거래와 상이한 위험 분포를 가짐**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd41c1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_online</th>\n",
       "      <th>fraud</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.122615</td>\n",
       "      <td>fraud_1_to_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.881249</td>\n",
       "      <td>fraud_1_to_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.044347</td>\n",
       "      <td>fraud_1_to_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.718060</td>\n",
       "      <td>fraud_1_to_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027198</td>\n",
       "      <td>fraud_1_to_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0.596927</td>\n",
       "      <td>fraud_1_to_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019536</td>\n",
       "      <td>fraud_1_to_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.518271</td>\n",
       "      <td>fraud_1_to_7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_online     fraud       dataset\n",
       "0          0  0.122615  fraud_1_to_1\n",
       "1          1  0.881249  fraud_1_to_1\n",
       "2          0  0.044347  fraud_1_to_3\n",
       "3          1  0.718060  fraud_1_to_3\n",
       "4          0  0.027198  fraud_1_to_5\n",
       "5          1  0.596927  fraud_1_to_5\n",
       "6          0  0.019536  fraud_1_to_7\n",
       "7          1  0.518271  fraud_1_to_7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_online = []\n",
    "\n",
    "for name in ratio_names:\n",
    "    df_s = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    df_s[\"is_online\"] = (\n",
    "        (df_s[\"merchant_state\"] == \"ONLINE\") |\n",
    "        (df_s[\"zip\"] == \"ONLINE\")\n",
    "    ).astype(int)\n",
    "\n",
    "    grp = (\n",
    "        df_s.groupby(\"is_online\")[\"fraud\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    grp[\"dataset\"] = name\n",
    "    eda_online.append(grp)\n",
    "\n",
    "eda_online_df = pd.concat(eda_online, ignore_index=True)\n",
    "eda_online_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9788e2e2",
   "metadata": {},
   "source": [
    "> **Fraud는 물리적 위치의 이탈보다는,** \\\n",
    "> **공간 정보가 사라진 거래 환경(ONLINE)에서 구조적으로 발생한다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41ec4be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 6 out of 6 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 6 out of 6 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 6 out of 6 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2385: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-X))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/discrete/discrete_model.py:2443: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.sum(np.log(self.cdf(q * linpred)))\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:71: ConvergenceWarning: QC check did not pass for 6 out of 6 parameters\n",
      "Try increasing solver accuracy or number of iterations, decreasing alpha, or switch solvers\n",
      "  warnings.warn(message, ConvergenceWarning)\n",
      "/home/nakyung/.local/lib/python3.10/site-packages/statsmodels/base/l1_solvers_common.py:144: ConvergenceWarning: Could not trim params automatically due to failed QC check. Trimming using trim_mode == 'size' will still work.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>variable</th>\n",
       "      <th>beta</th>\n",
       "      <th>odds_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fraud_1_to_1</td>\n",
       "      <td>is_online</td>\n",
       "      <td>2.084801</td>\n",
       "      <td>8.042994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fraud_1_to_3</td>\n",
       "      <td>is_online</td>\n",
       "      <td>2.091004</td>\n",
       "      <td>8.093038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fraud_1_to_5</td>\n",
       "      <td>is_online</td>\n",
       "      <td>2.072545</td>\n",
       "      <td>7.945015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fraud_1_to_7</td>\n",
       "      <td>is_online</td>\n",
       "      <td>2.095096</td>\n",
       "      <td>8.126223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset   variable      beta  odds_ratio\n",
       "0  fraud_1_to_1  is_online  2.084801    8.042994\n",
       "1  fraud_1_to_3  is_online  2.091004    8.093038\n",
       "2  fraud_1_to_5  is_online  2.072545    7.945015\n",
       "3  fraud_1_to_7  is_online  2.095096    8.126223"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for name in ratio_names:\n",
    "    df = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    # features\n",
    "    df[\"is_online\"] = (\n",
    "        (df[\"merchant_state\"] == \"ONLINE\") |\n",
    "        (df[\"zip\"] == \"ONLINE\")\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"hour\"] = df[\"date\"].dt.hour\n",
    "    df[\"is_off_hour\"] = ((df[\"hour\"] <= 5) | (df[\"hour\"] >= 22)).astype(int)\n",
    "\n",
    "    y = df[\"fraud\"].astype(int)\n",
    "\n",
    "    X = df[[\"is_online\", \"amount\", \"use_chip\", \"is_off_hour\"]].copy()\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "    X = sm.add_constant(X, has_constant=\"add\").astype(float)\n",
    "\n",
    "    # regularized logit (L2)\n",
    "    model = sm.Logit(y, X).fit_regularized(\n",
    "        method=\"l1\",      # l1로 두되\n",
    "        alpha=1e-6,       # alpha를 아주 작게(거의 MLE처럼)\n",
    "        disp=False\n",
    "    )\n",
    "\n",
    "    # 결과 저장\n",
    "    beta = float(model.params[\"is_online\"])\n",
    "    results.append({\n",
    "        \"dataset\": name,\n",
    "        \"variable\": \"is_online\",\n",
    "        \"beta\": beta,\n",
    "        \"odds_ratio\": float(np.exp(beta))\n",
    "    })\n",
    "\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad028c69",
   "metadata": {},
   "source": [
    "## 4.3 WHAT — 금액·소비 합리성 분석\n",
    "\n",
    "### 목적\n",
    "\n",
    "- 거래 금액 및 업종이 **사용자 경제 수준 대비 합리적인지** 평가\n",
    "\n",
    "### 사용 컬럼\n",
    "\n",
    "**Transactions**\n",
    "\n",
    "- `amount`\n",
    "- `mcc`\n",
    "\n",
    "**User**\n",
    "\n",
    "- `yearly_income`\n",
    "- `total_debt`\n",
    "- `credit_score`\n",
    "\n",
    "**Card**\n",
    "\n",
    "- `credit_limit`\n",
    "- `card_type`\n",
    "- `card_brand`\n",
    "\n",
    "### 제외/축소 컬럼\n",
    "\n",
    "- `per_capita_income` (yearly_income으로 대체 가능)\n",
    "- card_brand는 보조 변수로 사용\n",
    "\n",
    "### 주요 가설\n",
    "\n",
    "- 소득·한도 대비 과도한 거래 금액에서 Fraud 증가\n",
    "- 사용자 과거 소비 이력에 없는 MCC에서 거래 발생 시 위험 증가\n",
    "- 저신용 + 고액 거래 조합에서 Fraud 증가\n",
    "\n",
    "### 파생 피처 후보\n",
    "\n",
    "- `amount_to_credit_limit_ratio`\n",
    "- `amount_to_income_ratio`\n",
    "- `is_new_mcc_for_user`\n",
    "- `mcc_risk_score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59036306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         dataset                variable  odds_ratio\n",
      "0   fraud_1_to_1  low_credit_high_amount    9.513825\n",
      "1   fraud_1_to_1     is_new_mcc_for_user    1.000000\n",
      "2   fraud_1_to_1             high_amount   10.473193\n",
      "3   fraud_1_to_3  low_credit_high_amount   12.981268\n",
      "4   fraud_1_to_3     is_new_mcc_for_user    2.999900\n",
      "5   fraud_1_to_3             high_amount    9.519464\n",
      "6   fraud_1_to_5  low_credit_high_amount    8.292954\n",
      "7   fraud_1_to_5     is_new_mcc_for_user    4.999800\n",
      "8   fraud_1_to_5             high_amount    9.558986\n",
      "9   fraud_1_to_7  low_credit_high_amount    7.016322\n",
      "10  fraud_1_to_7     is_new_mcc_for_user    6.999700\n",
      "11  fraud_1_to_7             high_amount    9.374694\n",
      "                 variable   mean_or    min_or     max_or\n",
      "0             high_amount  9.731584  9.374694  10.473193\n",
      "2  low_credit_high_amount  9.451092  7.016322  12.981268\n",
      "1     is_new_mcc_for_user  3.999850  1.000000   6.999700\n"
     ]
    }
   ],
   "source": [
    "def odds_ratio_2x2(df, var):\n",
    "    a = ((df[var] == 1) & (df.fraud == 1)).sum()\n",
    "    b = ((df[var] == 1) & (df.fraud == 0)).sum()\n",
    "    c = ((df[var] == 0) & (df.fraud == 1)).sum()\n",
    "    d = ((df[var] == 0) & (df.fraud == 0)).sum()\n",
    "\n",
    "    # Haldane–Anscombe correction (완전분리 대응)\n",
    "    a, b, c, d = a+0.5, b+0.5, c+0.5, d+0.5\n",
    "\n",
    "    return (a * d) / (b * c)\n",
    "\n",
    "\n",
    "what_results = []\n",
    "\n",
    "for name in ratio_names:\n",
    "    df = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    # user merge\n",
    "    df = df.merge(\n",
    "        user[[\"id\", \"yearly_income\", \"total_debt\", \"credit_score\"]],\n",
    "        left_on=\"client_id\",\n",
    "        right_on=\"id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    for col in [\"yearly_income\", \"total_debt\"]:\n",
    "        df[col] = df[col].replace(\"[\\$,]\", \"\", regex=True).astype(float)\n",
    "\n",
    "    # -----------------------\n",
    "    # WHAT 파생 변수\n",
    "    # -----------------------\n",
    "    df[\"amount_abs\"] = df[\"amount\"].abs()\n",
    "    df[\"amount_to_income_ratio\"] = df[\"amount_abs\"] / df[\"yearly_income\"].replace(0, np.nan)\n",
    "\n",
    "    high_thr = df[\"amount_to_income_ratio\"].quantile(0.95)\n",
    "    df[\"high_amount\"] = (df[\"amount_to_income_ratio\"] > high_thr).astype(int)\n",
    "\n",
    "    df[\"low_credit\"] = (df[\"credit_score\"] < 600).astype(int)\n",
    "    df[\"low_credit_high_amount\"] = (df[\"low_credit\"] & df[\"high_amount\"]).astype(int)\n",
    "\n",
    "    user_mcc_seen = (\n",
    "        df.groupby([\"client_id\", \"mcc\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"cnt\")\n",
    "    )\n",
    "    df = df.merge(\n",
    "        user_mcc_seen[[\"client_id\", \"mcc\"]],\n",
    "        on=[\"client_id\", \"mcc\"],\n",
    "        how=\"left\",\n",
    "        indicator=True\n",
    "    )\n",
    "    df[\"is_new_mcc_for_user\"] = (df[\"_merge\"] == \"left_only\").astype(int)\n",
    "    df.drop(columns=\"_merge\", inplace=True)\n",
    "\n",
    "    # -----------------------\n",
    "    # WHAT 변수 OR 계산\n",
    "    # -----------------------\n",
    "    for var in [\n",
    "        \"low_credit_high_amount\",\n",
    "        \"is_new_mcc_for_user\",\n",
    "        \"high_amount\"\n",
    "    ]:\n",
    "        or_val = odds_ratio_2x2(df, var)\n",
    "\n",
    "        what_results.append({\n",
    "            \"dataset\": name,\n",
    "            \"variable\": var,\n",
    "            \"odds_ratio\": or_val\n",
    "        })\n",
    "\n",
    "res_df = pd.DataFrame(what_results)\n",
    "\n",
    "summary = (\n",
    "    res_df\n",
    "    .groupby(\"variable\")\n",
    "    .agg(\n",
    "        mean_or=(\"odds_ratio\", \"mean\"),\n",
    "        min_or=(\"odds_ratio\", \"min\"),\n",
    "        max_or=(\"odds_ratio\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\"mean_or\", ascending=False)\n",
    ")\n",
    "\n",
    "print(res_df)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f53b1",
   "metadata": {},
   "source": [
    "> 소득 대비 과도한 금액의 거래는\\\n",
    "> Fraud 발생 확률을 약 10배 증가시킨다.\n",
    "\n",
    "\n",
    "> 저신용 상태에서 발생한 고액 거래는\\\n",
    "> Fraud 위험을 증폭\n",
    "\n",
    "\n",
    "> 신규 업종 거래는 fraud가 발생할 때 자주 동반"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf701986",
   "metadata": {},
   "source": [
    "## 4.4 HOW — 결제 방식 및 오류 패턴 분석\n",
    "\n",
    "### 목적\n",
    "\n",
    "- 결제 수단·오류 로그의 **물리적/논리적 일관성 검증**\n",
    "\n",
    "### 사용 컬럼\n",
    "\n",
    "**Transactions**\n",
    "\n",
    "- `use_chip`\n",
    "- `has_error`\n",
    "- `err_card_credential`\n",
    "- `err_authentication`\n",
    "- `err_financial`\n",
    "- `err_system`\n",
    "\n",
    "**Card**\n",
    "\n",
    "- `has_chip`\n",
    "\n",
    "### 주요 가설\n",
    "\n",
    "- 칩 미보유 카드에서 Chip Transaction 발생 시 이상 거래 가능성 증가\n",
    "- 오류 발생 후 연속 재시도 거래에서 Fraud 위험 증가\n",
    "- 인증 오류 후 즉시 성공 거래 패턴은 Fraud 가능성 증가\n",
    "\n",
    "### 파생 피처 후보\n",
    "\n",
    "- `chip_mismatch_flag`\n",
    "- `error_count_recent_window`\n",
    "- `error_then_success_flag`\n",
    "- `error_type_diversity`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf3eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               variable      beta  odds_ratio        pvalue       dataset\n",
      "0             any_error  1.168902    3.218458  1.779333e-32  fraud_1_to_1\n",
      "1  error_type_diversity  1.166093    3.209430  1.361182e-32  fraud_1_to_1\n",
      "2             any_error  0.944677    2.571982  2.261393e-46  fraud_1_to_3\n",
      "3  error_type_diversity  0.927563    2.528339  7.272621e-46  fraud_1_to_3\n",
      "4             any_error  1.041431    2.833268  9.505866e-66  fraud_1_to_5\n",
      "5  error_type_diversity  1.034757    2.814422  3.881808e-66  fraud_1_to_5\n",
      "6             any_error  1.042536    2.836402  6.012449e-73  fraud_1_to_7\n",
      "7  error_type_diversity  1.031490    2.805243  4.187527e-73  fraud_1_to_7\n",
      "               variable  sign_consistent  significant_cnt   mean_or    min_or  \\\n",
      "0             any_error             True                4  2.865027  2.571982   \n",
      "1  error_type_diversity             True                4  2.839359  2.528339   \n",
      "\n",
      "     max_or  \n",
      "0  3.218458  \n",
      "1  3.209430  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# HOW — 결제 방식 & 오류 패턴\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "base_path = \"data/sampling\"\n",
    "ratio_names = [\n",
    "    \"fraud_1_to_1\",\n",
    "    \"fraud_1_to_3\",\n",
    "    \"fraud_1_to_5\",\n",
    "    \"fraud_1_to_7\"\n",
    "]\n",
    "\n",
    "how_results = []\n",
    "\n",
    "def univariate_logit(df, var):\n",
    "    y = df[\"fraud\"].astype(int)\n",
    "    X = sm.add_constant(df[[var]].fillna(0))\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "    return {\n",
    "        \"variable\": var,\n",
    "        \"beta\": model.params[var],\n",
    "        \"odds_ratio\": np.exp(model.params[var]),\n",
    "        \"pvalue\": model.pvalues[var],\n",
    "    }\n",
    "\n",
    "for name in ratio_names:\n",
    "\n",
    "    # 데이터 로드\n",
    "\n",
    "    df = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    # card merge\n",
    "\n",
    "    df = df.merge(\n",
    "        card[[\"id\", \"has_chip\"]],\n",
    "        left_on=\"card_id\",\n",
    "        right_on=\"id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # 파생 변수\n",
    "    df[\"chip_mismatch_flag\"] = (\n",
    "        (df[\"has_chip\"] == \"NO\") &\n",
    "        (df[\"use_chip\"] == \"Chip Transaction\")\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"any_error\"] = (\n",
    "        df[\"err_card_credential\"] |\n",
    "        df[\"err_authentication\"] |\n",
    "        df[\"err_financial\"] |\n",
    "        df[\"err_system\"]\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"error_type_diversity\"] = (\n",
    "        df[\n",
    "            [\n",
    "                \"err_card_credential\",\n",
    "                \"err_authentication\",\n",
    "                \"err_financial\",\n",
    "                \"err_system\"\n",
    "            ]\n",
    "        ].sum(axis=1)\n",
    "    )\n",
    "\n",
    "    # ---------------------------\n",
    "    # 단변수 로지스틱\n",
    "    # ---------------------------\n",
    "    for var in [\n",
    "        \"chip_mismatch_flag\",\n",
    "        \"any_error\",\n",
    "        \"error_type_diversity\",\n",
    "    ]:\n",
    "        try:\n",
    "            res = univariate_logit(df, var)\n",
    "            res[\"dataset\"] = name\n",
    "            how_results.append(res)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "# 결과 요약\n",
    "\n",
    "res_df = pd.DataFrame(how_results)\n",
    "\n",
    "summary = (\n",
    "    res_df\n",
    "    .groupby(\"variable\")\n",
    "    .agg(\n",
    "        sign_consistent=(\"beta\", lambda x: len(set(np.sign(x))) == 1),\n",
    "        significant_cnt=(\"pvalue\", lambda x: (x < 0.05).sum()),\n",
    "        mean_or=(\"odds_ratio\", \"mean\"),\n",
    "        min_or=(\"odds_ratio\", \"min\"),\n",
    "        max_or=(\"odds_ratio\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\n",
    "        [\"sign_consistent\", \"significant_cnt\"],\n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "\n",
    "print(res_df)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45935051",
   "metadata": {},
   "source": [
    "> **오류가 발생하고 유형이 다양할수록 fraud 확률 증가**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbd495a",
   "metadata": {},
   "source": [
    "\n",
    "## 4.5 WHO — 사용자 특성 기반 분석\n",
    "\n",
    "### 목적\n",
    "\n",
    "- Fraud에 **상대적으로 취약한 사용자 특성 탐색**\n",
    "\n",
    "### 사용 컬럼\n",
    "\n",
    "**User**\n",
    "\n",
    "- `gender`\n",
    "- `num_credit_cards`\n",
    "- `credit_score`\n",
    "- `birth_year` (나이 계산용)\n",
    "\n",
    "**Card**\n",
    "\n",
    "- `num_cards_issued`\n",
    "- `card_on_dark_web`\n",
    "\n",
    "### 제외/축소 컬럼\n",
    "\n",
    "- `birth_month`\n",
    "- `retirement_age`\n",
    "\n",
    "### 해석 주의사항\n",
    "\n",
    "- 성별 등 인구통계 변수는 **단독 판단 근거로 사용하지 않음**\n",
    "- 다른 패턴 변수와 결합하여 보조적으로 해석\n",
    "\n",
    "### 주요 가설\n",
    "\n",
    "- 다수 카드 보유 고객에서 관리 복잡도 증가로 Fraud 발생 가능성 증가\n",
    "- 다크웹 노출 카드 보유 시 Fraud 위험 증가\n",
    "- 저신용 사용자에서 Fraud 피해 취약성 증가\n",
    "- 사용자 나이가 높을수록 fraud 취약성 증가\n",
    "\n",
    "### 파생 피처 후보\n",
    "\n",
    "- `cards_per_user`\n",
    "- `darkweb_card_ratio`\n",
    "- `user_risk_segment`\n",
    "- `age_at_transaction`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5995dcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              variable      beta  odds_ratio        pvalue       dataset\n",
      "0   age_at_transaction  0.003388    1.003394  1.684325e-04  fraud_1_to_1\n",
      "1           low_credit -0.196010    0.822004  1.702819e-03  fraud_1_to_1\n",
      "2           many_cards  0.295499    1.343797  4.314265e-23  fraud_1_to_1\n",
      "3   age_at_transaction  0.003098    1.003103  1.898066e-05  fraud_1_to_3\n",
      "4           low_credit -0.194228    0.823470  1.937962e-04  fraud_1_to_3\n",
      "5           many_cards  0.296899    1.345679  7.029567e-35  fraud_1_to_3\n",
      "6   age_at_transaction  0.003027    1.003032  1.080638e-05  fraud_1_to_5\n",
      "7           low_credit -0.184553    0.831476  2.112967e-04  fraud_1_to_5\n",
      "8           many_cards  0.291864    1.338921  1.269737e-37  fraud_1_to_5\n",
      "9   age_at_transaction  0.003405    1.003410  3.655650e-07  fraud_1_to_7\n",
      "10          low_credit -0.196010    0.822004  5.783234e-05  fraud_1_to_7\n",
      "11          many_cards  0.302304    1.352973  2.677791e-42  fraud_1_to_7\n",
      "             variable  sign_consistent  significant_cnt   mean_or    min_or  \\\n",
      "0  age_at_transaction             True                4  1.003235  1.003032   \n",
      "1          low_credit             True                4  0.824738  0.822004   \n",
      "2          many_cards             True                4  1.345343  1.338921   \n",
      "\n",
      "     max_or  \n",
      "0  1.003410  \n",
      "1  0.831476  \n",
      "2  1.352973  \n"
     ]
    }
   ],
   "source": [
    "who_results = []\n",
    "\n",
    "def univariate_logit(df, var):\n",
    "    y = df[\"fraud\"].astype(int)\n",
    "    X = sm.add_constant(df[[var]].fillna(0))\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "\n",
    "    return {\n",
    "        \"variable\": var,\n",
    "        \"beta\": model.params[var],\n",
    "        \"odds_ratio\": np.exp(model.params[var]),\n",
    "        \"pvalue\": model.pvalues[var],\n",
    "    }\n",
    "\n",
    "for name in ratio_names:\n",
    "\n",
    "    # 데이터 로드\n",
    "\n",
    "    df = pd.read_parquet(f\"{base_path}/{name}/data.parquet\")\n",
    "\n",
    "    # user + card merge\n",
    "\n",
    "    df = df.merge(\n",
    "        user[\n",
    "            [\n",
    "                \"id\",\n",
    "                \"gender\",\n",
    "                \"birth_year\",\n",
    "                \"credit_score\",\n",
    "                \"num_credit_cards\",\n",
    "            ]\n",
    "        ],\n",
    "        left_on=\"client_id\",\n",
    "        right_on=\"id\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    df = df.merge(\n",
    "        card[\n",
    "            [\n",
    "                \"id\",\n",
    "                \"num_cards_issued\",\n",
    "                \"card_on_dark_web\",\n",
    "            ]\n",
    "        ],\n",
    "        left_on=\"card_id\",\n",
    "        right_on=\"id\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_card\")\n",
    "    )\n",
    "\n",
    "    # 파생 변수\n",
    "\n",
    "    df[\"txn_year\"] = df[\"date\"].dt.year\n",
    "    df[\"age_at_transaction\"] = df[\"txn_year\"] - df[\"birth_year\"]\n",
    "\n",
    "    df[\"cards_per_user\"] = df[\"num_credit_cards\"]\n",
    "\n",
    "    df[\"darkweb_card\"] = (\n",
    "        df[\"card_on_dark_web\"] == \"Yes\"\n",
    "    ).astype(int)\n",
    "\n",
    "    df[\"low_credit\"] = (df[\"credit_score\"] < 600).astype(int)\n",
    "\n",
    "    df[\"many_cards\"] = (df[\"cards_per_user\"] >= 5).astype(int)\n",
    "\n",
    "\n",
    "    # WHO 변수 단독 검증\n",
    "\n",
    "    for var in [\n",
    "        \"age_at_transaction\",\n",
    "        \"low_credit\",\n",
    "        \"many_cards\",\n",
    "        \"darkweb_card\",\n",
    "    ]:\n",
    "        try:\n",
    "            res = univariate_logit(df, var)\n",
    "            res[\"dataset\"] = name\n",
    "            who_results.append(res)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "\n",
    "res_df = pd.DataFrame(who_results)\n",
    "\n",
    "summary = (\n",
    "    res_df\n",
    "    .groupby(\"variable\")\n",
    "    .agg(\n",
    "        sign_consistent=(\"beta\", lambda x: len(set(np.sign(x))) == 1),\n",
    "        significant_cnt=(\"pvalue\", lambda x: (x < 0.05).sum()),\n",
    "        mean_or=(\"odds_ratio\", \"mean\"),\n",
    "        min_or=(\"odds_ratio\", \"min\"),\n",
    "        max_or=(\"odds_ratio\", \"max\"),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .sort_values(\n",
    "        [\"sign_consistent\", \"significant_cnt\"],\n",
    "        ascending=False\n",
    "    )\n",
    ")\n",
    "\n",
    "print(res_df)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9cad96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc205bb3",
   "metadata": {},
   "source": [
    "---\n",
    "# Result\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffdf048",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU-CAT)",
   "language": "python",
   "name": "gpu-cat"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
